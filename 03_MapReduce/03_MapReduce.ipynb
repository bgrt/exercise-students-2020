{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MapReduce\n",
    "\n",
    "For this exercise we are going to use MapReduce in local mode, i.e. we won't be running anything on the cluster!\n",
    " \n",
    "## 3.1. Use the commands `head`, `cat`, `uniq`, `wc`, `sort`, `find`, `xargs`, `awk` to evaluate the NASA log file:\n",
    "\n",
    "* Data File:  <https://github.com/scalable-infrastructure/exercise-2018/blob/master/data/nasa/NASA_access_log_Jul95.gz>\n",
    "* Which page was called the most?\n",
    "* What was the most frequent return code?\n",
    "* How many errors occurred? What is the percentage of errors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "os.chdir(os.path.join(os.environ[\"HOME\"], \"exercise-students-2020/03_MapReduce\"))\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245\n",
      "unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985\n",
      "199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085\n",
      "burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0\n",
      "199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179\n",
      "burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0\n",
      "burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0\n",
      "205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985\n",
      "d104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985\n",
      "129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074\n"
     ]
    }
   ],
   "source": [
    "!head /opt/data/nasa/NASA_access_log_Jul95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  17572 piweba3y.prodigy.com\n",
      "sort: write failed: 'standard output': Broken pipe\n",
      "sort: write error\n"
     ]
    }
   ],
   "source": [
    "#Which page was called the most? (Answer: number_of_calls, website)\n",
    "!awk '{print $1}' /opt/data/nasa/NASA_access_log_Jul95 | sort -n | uniq -c | sort -nr | head -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1701534 200\n"
     ]
    }
   ],
   "source": [
    "#What was the most frequent return code? (Answer: number_of_code, code)\n",
    "! awk '{print $(NF-1)}' /opt/data/nasa/NASA_access_log_Jul95 | sort -n | uniq -c | sort -nr | head -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of errors: 10981\n",
      "Error percentage: 0.580479%\n"
     ]
    }
   ],
   "source": [
    "#How many errors occurred? What is the percentage of errors?\n",
    "!x=\"$(wc -l /opt/data/nasa/NASA_access_log_Jul95 | awk '{print $1}') $(awk '$(NF-1) >= 400 {print $(NF-1)}' /opt/data/nasa/NASA_access_log_Jul95 | wc -l)\"; echo $x | awk '{print \"Total num of errors: \" $2}'; echo $x | awk '{print \"Error percentage: \"($2 / ($1) * 100) \"%\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Implement a Python version of this Unix Shell script using this script as template! Run the Python script inside an Hadoop Streaming job.\n",
    "\n",
    "Template: <https://github.com/scalable-infrastructure/scalable-infrastructure.github.io/blob/master/src/map_reduce.py>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TMP_DIR=os.path.join(os.getcwd(), \"tmp\")\n",
    "os.environ[\"HADOOP_HOME\"]=\"/opt/hadoop-2.8.5\"\n",
    "os.environ[\"JAVA_HOME\"]=\"/usr\"\n",
    "os.environ[\"JAVA_OPTS\"]=\"-Djava.io.tmpdir=\"+TMP_DIR\n",
    "os.environ[\"HADOOP_OPTS\"]=\"-Djava.io.tmpdir=\"+TMP_DIR\n",
    "os.environ[\"PATH\"]=os.path.join(os.environ[\"HADOOP_HOME\"], \"bin\") + \":\"+os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar [options]\n",
      "Options:\n",
      "  -input          <path> DFS input file(s) for the Map step.\n",
      "  -output         <path> DFS output directory for the Reduce step.\n",
      "  -mapper         <cmd|JavaClassName> Optional. Command to be run as mapper.\n",
      "  -combiner       <cmd|JavaClassName> Optional. Command to be run as combiner.\n",
      "  -reducer        <cmd|JavaClassName> Optional. Command to be run as reducer.\n",
      "  -file           <file> Optional. File/dir to be shipped in the Job jar file.\n",
      "                  Deprecated. Use generic option \"-files\" instead.\n",
      "  -inputformat    <TextInputFormat(default)|SequenceFileAsTextInputFormat|JavaClassName>\n",
      "                  Optional. The input format class.\n",
      "  -outputformat   <TextOutputFormat(default)|JavaClassName>\n",
      "                  Optional. The output format class.\n",
      "  -partitioner    <JavaClassName>  Optional. The partitioner class.\n",
      "  -numReduceTasks <num> Optional. Number of reduce tasks.\n",
      "  -inputreader    <spec> Optional. Input recordreader spec.\n",
      "  -cmdenv         <n>=<v> Optional. Pass env.var to streaming commands.\n",
      "  -mapdebug       <cmd> Optional. To run this script when a map task fails.\n",
      "  -reducedebug    <cmd> Optional. To run this script when a reduce task fails.\n",
      "  -io             <identifier> Optional. Format to use for input to and output\n",
      "                  from mapper/reducer commands\n",
      "  -lazyOutput     Optional. Lazily create Output.\n",
      "  -background     Optional. Submit the job and don't wait till it completes.\n",
      "  -verbose        Optional. Print verbose output.\n",
      "  -info           Optional. Print detailed usage.\n",
      "  -help           Optional. Print help message.\n",
      "\n",
      "Generic options supported are\n",
      "-conf <configuration file>     specify an application configuration file\n",
      "-D <property=value>            use value for given property\n",
      "-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.\n",
      "-jt <local|resourcemanager:port>    specify a ResourceManager\n",
      "-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster\n",
      "-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.\n",
      "-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.\n",
      "\n",
      "The general command line syntax is\n",
      "command [genericOptions] [commandOptions]\n",
      "\n",
      "\n",
      "Usage tips:\n",
      "In -input: globbing on <path> is supported and can have multiple -input\n",
      "\n",
      "Default Map input format: a line is a record in UTF-8 the key part ends at first\n",
      "  TAB, the rest of the line is the value\n",
      "\n",
      "To pass a Custom input format:\n",
      "  -inputformat package.MyInputFormat\n",
      "\n",
      "Similarly, to pass a custom output format:\n",
      "  -outputformat package.MyOutputFormat\n",
      "\n",
      "The files with extensions .class and .jar/.zip, specified for the -file\n",
      "  argument[s], end up in \"classes\" and \"lib\" directories respectively inside\n",
      "  the working directory when the mapper and reducer are run. All other files\n",
      "  specified for the -file argument[s] end up in the working directory when the\n",
      "  mapper and reducer are run. The location of this working directory is\n",
      "  unspecified.\n",
      "\n",
      "To set the number of reduce tasks (num. of output files) as, say 10:\n",
      "  Use -numReduceTasks 10\n",
      "To skip the sort/combine/shuffle/sort/reduce step:\n",
      "  Use -numReduceTasks 0\n",
      "  Map output then becomes a 'side-effect output' rather than a reduce input.\n",
      "  This speeds up processing. This also feels more like \"in-place\" processing\n",
      "  because the input filename and the map input order are preserved.\n",
      "  This is equivalent to -reducer NONE\n",
      "\n",
      "To speed up the last maps:\n",
      "  -D mapreduce.map.speculative=true\n",
      "To speed up the last reduces:\n",
      "  -D mapreduce.reduce.speculative=true\n",
      "To name the job (appears in the JobTracker Web UI):\n",
      "  -D mapreduce.job.name='My Job'\n",
      "To change the local temp directory:\n",
      "  -D dfs.data.dir=/tmp/dfs\n",
      "  -D stream.tmpdir=/tmp/streaming\n",
      "Additional local temp directories with -jt local:\n",
      "  -D mapreduce.cluster.local.dir=/tmp/local\n",
      "  -D mapreduce.jobtracker.system.dir=/tmp/system\n",
      "  -D mapreduce.cluster.temp.dir=/tmp/temp\n",
      "To treat tasks with non-zero exit status as SUCCEDED:\n",
      "  -D stream.non.zero.exit.is.failure=false\n",
      "Use a custom hadoop streaming build along with standard hadoop install:\n",
      "  $HADOOP_PREFIX/bin/hadoop jar /path/my-hadoop-streaming.jar [...]\\\n",
      "    [...] -D stream.shipped.hadoopstreaming=/path/my-hadoop-streaming.jar\n",
      "For more details about jobconf parameters see:\n",
      "  http://wiki.apache.org/hadoop/JobConfFile\n",
      "Truncate the values of the job configuration copiedto the environment at the given length:\n",
      "   -D stream.jobconf.truncate.limit=-1\n",
      "To set an environment variable in a streaming command:\n",
      "   -cmdenv EXAMPLE_DIR=/home/example/dictionaries/\n",
      "\n",
      "Shortcut:\n",
      "   setenv HSTREAMING \"$HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar\"\n",
      "\n",
      "Example: $HSTREAMING -mapper \"/usr/local/bin/perl5 filter.pl\"\n",
      "           -file /local/filter.pl -input \"/logs/0604*/*\" [...]\n",
      "  Ships a script, invokes the non-shipped perl interpreter. Shipped files go to\n",
      "  the working directory so filter.pl is found by perl. Input files are all the\n",
      "  daily logs for days in month 2006-04\n"
     ]
    }
   ],
   "source": [
    "!hadoop jar ${HADOOP_HOME}/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar -info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\t10980\n",
      "ok\t1880734\n"
     ]
    }
   ],
   "source": [
    "!cat /opt/data/nasa/NASA_access_log_Jul95| python map_reduce.py map | sort | python map_reduce.py reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/04/14 16:21:09 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "20/04/14 16:21:09 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "20/04/14 16:21:09 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "20/04/14 16:21:09 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "20/04/14 16:21:09 INFO mapreduce.JobSubmitter: number of splits:7\n",
      "20/04/14 16:21:09 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local112663626_0001\n",
      "20/04/14 16:21:09 INFO mapred.LocalDistributedCacheManager: Localized file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/map_reduce.py as file:/tmp/hadoop-jupyter-ter-akopyan-118531-8d8bf/mapred/local/1586881269915/map_reduce.py\n",
      "20/04/14 16:21:10 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "20/04/14 16:21:10 INFO mapreduce.Job: Running job: job_local112663626_0001\n",
      "20/04/14 16:21:10 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "20/04/14 16:21:10 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "20/04/14 16:21:10 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:21:10 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:21:10 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "20/04/14 16:21:10 INFO mapred.LocalJobRunner: Starting task: attempt_local112663626_0001_m_000000_0\n",
      "20/04/14 16:21:10 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:21:10 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:21:10 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:21:10 INFO mapred.MapTask: Processing split: file:/opt/data/nasa/NASA_access_log_Jul95:0+33554432\n",
      "20/04/14 16:21:10 INFO mapred.MapTask: numReduceTasks: 1\n",
      "20/04/14 16:21:10 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:21:10 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:21:10 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:21:10 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:21:10 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:21:10 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:21:10 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/./map_reduce.py, map]\n",
      "20/04/14 16:21:10 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "20/04/14 16:21:10 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "20/04/14 16:21:10 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "20/04/14 16:21:10 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "20/04/14 16:21:10 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "20/04/14 16:21:10 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "20/04/14 16:21:10 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "20/04/14 16:21:10 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "20/04/14 16:21:10 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "20/04/14 16:21:10 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "20/04/14 16:21:10 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "20/04/14 16:21:10 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "20/04/14 16:21:10 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:10 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:10 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:10 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:10 INFO streaming.PipeMapRed: Records R/W=2750/1\n",
      "20/04/14 16:21:10 INFO streaming.PipeMapRed: R/W/S=10000/8166/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:10 INFO streaming.PipeMapRed: R/W/S=100000/98038/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:10 INFO streaming.PipeMapRed: R/W/S=200000/197680/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:10 INFO streaming.PipeMapRed: R/W/S=300000/297822/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:10 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "20/04/14 16:21:10 INFO streaming.PipeMapRed: mapRedFinished\n",
      "20/04/14 16:21:10 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:21:10 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:21:10 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:21:10 INFO mapred.MapTask: bufstart = 0; bufend = 1529130; bufvoid = 104857600\n",
      "20/04/14 16:21:10 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24995020(99980080); length = 1219377/6553600\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:21:11 INFO mapred.Task: Task:attempt_local112663626_0001_m_000000_0 is done. And is in the process of committing\n",
      "20/04/14 16:21:11 INFO mapred.LocalJobRunner: Records R/W=2750/1\n",
      "20/04/14 16:21:11 INFO mapred.Task: Task 'attempt_local112663626_0001_m_000000_0' done.\n",
      "20/04/14 16:21:11 INFO mapred.Task: Final Counters for attempt_local112663626_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=33695783\n",
      "\t\tFILE: Number of bytes written=2701612\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=304845\n",
      "\t\tMap output records=304845\n",
      "\t\tMap output bytes=1529130\n",
      "\t\tMap output materialized bytes=2138826\n",
      "\t\tInput split bytes=93\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=304845\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "20/04/14 16:21:11 INFO mapred.LocalJobRunner: Finishing task: attempt_local112663626_0001_m_000000_0\n",
      "20/04/14 16:21:11 INFO mapred.LocalJobRunner: Starting task: attempt_local112663626_0001_m_000001_0\n",
      "20/04/14 16:21:11 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:21:11 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:21:11 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: Processing split: file:/opt/data/nasa/NASA_access_log_Jul95:33554432+33554432\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: numReduceTasks: 1\n",
      "20/04/14 16:21:11 INFO mapreduce.Job: Job job_local112663626_0001 running in uber mode : false\n",
      "20/04/14 16:21:11 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/./map_reduce.py, map]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: Records R/W=2438/1\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=10000/8177/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=100000/98028/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=200000/197610/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=300000/297153/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: mapRedFinished\n",
      "20/04/14 16:21:11 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:21:11 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: bufstart = 0; bufend = 1548324; bufvoid = 104857600\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24980452(99921808); length = 1233945/6553600\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:21:11 INFO mapred.Task: Task:attempt_local112663626_0001_m_000001_0 is done. And is in the process of committing\n",
      "20/04/14 16:21:11 INFO mapred.LocalJobRunner: Records R/W=2438/1\n",
      "20/04/14 16:21:11 INFO mapred.Task: Task 'attempt_local112663626_0001_m_000001_0' done.\n",
      "20/04/14 16:21:11 INFO mapred.Task: Final Counters for attempt_local112663626_0001_m_000001_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67254985\n",
      "\t\tFILE: Number of bytes written=4866948\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=308487\n",
      "\t\tMap output records=308487\n",
      "\t\tMap output bytes=1548324\n",
      "\t\tMap output materialized bytes=2165304\n",
      "\t\tInput split bytes=93\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=308487\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "20/04/14 16:21:11 INFO mapred.LocalJobRunner: Finishing task: attempt_local112663626_0001_m_000001_0\n",
      "20/04/14 16:21:11 INFO mapred.LocalJobRunner: Starting task: attempt_local112663626_0001_m_000002_0\n",
      "20/04/14 16:21:11 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:21:11 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:21:11 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: Processing split: file:/opt/data/nasa/NASA_access_log_Jul95:67108864+33554432\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: numReduceTasks: 1\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:21:11 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/./map_reduce.py, map]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: Records R/W=2407/1\n",
      "20/04/14 16:21:11 INFO streaming.PipeMapRed: R/W/S=10000/8154/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: R/W/S=100000/97951/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: R/W/S=200000/197584/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: R/W/S=300000/297596/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: mapRedFinished\n",
      "20/04/14 16:21:12 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:21:12 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: bufstart = 0; bufend = 1559933; bufvoid = 104857600\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24970632(99882528); length = 1243765/6553600\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:21:12 INFO mapred.Task: Task:attempt_local112663626_0001_m_000002_0 is done. And is in the process of committing\n",
      "20/04/14 16:21:12 INFO mapred.LocalJobRunner: Records R/W=2407/1\n",
      "20/04/14 16:21:12 INFO mapred.Task: Task 'attempt_local112663626_0001_m_000002_0' done.\n",
      "20/04/14 16:21:12 INFO mapred.Task: Final Counters for attempt_local112663626_0001_m_000002_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=100814187\n",
      "\t\tFILE: Number of bytes written=7048803\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=310942\n",
      "\t\tMap output records=310942\n",
      "\t\tMap output bytes=1559933\n",
      "\t\tMap output materialized bytes=2181823\n",
      "\t\tInput split bytes=93\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=310942\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "20/04/14 16:21:12 INFO mapred.LocalJobRunner: Finishing task: attempt_local112663626_0001_m_000002_0\n",
      "20/04/14 16:21:12 INFO mapred.LocalJobRunner: Starting task: attempt_local112663626_0001_m_000003_0\n",
      "20/04/14 16:21:12 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:21:12 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:21:12 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: Processing split: file:/opt/data/nasa/NASA_access_log_Jul95:100663296+33554432\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: numReduceTasks: 1\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/./map_reduce.py, map]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: Records R/W=2506/1\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: R/W/S=10000/8182/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: R/W/S=100000/98079/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: R/W/S=200000/197740/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: R/W/S=300000/297397/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "20/04/14 16:21:12 INFO streaming.PipeMapRed: mapRedFinished\n",
      "20/04/14 16:21:12 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:21:12 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: bufstart = 0; bufend = 1548717; bufvoid = 104857600\n",
      "20/04/14 16:21:12 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24979108(99916432); length = 1235289/6553600\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:21:13 INFO mapred.Task: Task:attempt_local112663626_0001_m_000003_0 is done. And is in the process of committing\n",
      "20/04/14 16:21:13 INFO mapred.LocalJobRunner: Records R/W=2506/1\n",
      "20/04/14 16:21:13 INFO mapred.Task: Task 'attempt_local112663626_0001_m_000003_0' done.\n",
      "20/04/14 16:21:13 INFO mapred.Task: Final Counters for attempt_local112663626_0001_m_000003_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=134373389\n",
      "\t\tFILE: Number of bytes written=9215204\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=308823\n",
      "\t\tMap output records=308823\n",
      "\t\tMap output bytes=1548717\n",
      "\t\tMap output materialized bytes=2166369\n",
      "\t\tInput split bytes=93\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=308823\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=21\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "20/04/14 16:21:13 INFO mapred.LocalJobRunner: Finishing task: attempt_local112663626_0001_m_000003_0\n",
      "20/04/14 16:21:13 INFO mapred.LocalJobRunner: Starting task: attempt_local112663626_0001_m_000004_0\n",
      "20/04/14 16:21:13 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:21:13 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:21:13 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: Processing split: file:/opt/data/nasa/NASA_access_log_Jul95:134217728+33554432\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: numReduceTasks: 1\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/./map_reduce.py, map]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: Records R/W=2450/1\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=10000/8174/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=100000/97938/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=200000/197433/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=300000/297050/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: mapRedFinished\n",
      "20/04/14 16:21:13 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:21:13 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: bufstart = 0; bufend = 1561461; bufvoid = 104857600\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24970312(99881248); length = 1244085/6553600\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:21:13 INFO mapred.Task: Task:attempt_local112663626_0001_m_000004_0 is done. And is in the process of committing\n",
      "20/04/14 16:21:13 INFO mapred.LocalJobRunner: Records R/W=2450/1\n",
      "20/04/14 16:21:13 INFO mapred.Task: Task 'attempt_local112663626_0001_m_000004_0' done.\n",
      "20/04/14 16:21:13 INFO mapred.Task: Final Counters for attempt_local112663626_0001_m_000004_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=167932591\n",
      "\t\tFILE: Number of bytes written=11398747\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=311022\n",
      "\t\tMap output records=311022\n",
      "\t\tMap output bytes=1561461\n",
      "\t\tMap output materialized bytes=2183511\n",
      "\t\tInput split bytes=93\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=311022\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=15\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "20/04/14 16:21:13 INFO mapred.LocalJobRunner: Finishing task: attempt_local112663626_0001_m_000004_0\n",
      "20/04/14 16:21:13 INFO mapred.LocalJobRunner: Starting task: attempt_local112663626_0001_m_000005_0\n",
      "20/04/14 16:21:13 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:21:13 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:21:13 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: Processing split: file:/opt/data/nasa/NASA_access_log_Jul95:167772160+33554432\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: numReduceTasks: 1\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:21:13 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/./map_reduce.py, map]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: Records R/W=2416/1\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=10000/8170/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=100000/97717/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:13 INFO streaming.PipeMapRed: R/W/S=200000/197588/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:14 INFO streaming.PipeMapRed: R/W/S=300000/298150/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:14 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "20/04/14 16:21:14 INFO streaming.PipeMapRed: mapRedFinished\n",
      "20/04/14 16:21:14 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:21:14 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: bufstart = 0; bufend = 1560945; bufvoid = 104857600\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24970072(99880288); length = 1244325/6553600\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:21:14 INFO mapred.Task: Task:attempt_local112663626_0001_m_000005_0 is done. And is in the process of committing\n",
      "20/04/14 16:21:14 INFO mapred.LocalJobRunner: Records R/W=2416/1\n",
      "20/04/14 16:21:14 INFO mapred.Task: Task 'attempt_local112663626_0001_m_000005_0' done.\n",
      "20/04/14 16:21:14 INFO mapred.Task: Final Counters for attempt_local112663626_0001_m_000005_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=201491793\n",
      "\t\tFILE: Number of bytes written=13581894\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=311082\n",
      "\t\tMap output records=311082\n",
      "\t\tMap output bytes=1560945\n",
      "\t\tMap output materialized bytes=2183115\n",
      "\t\tInput split bytes=93\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=311082\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=14\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33558528\n",
      "20/04/14 16:21:14 INFO mapred.LocalJobRunner: Finishing task: attempt_local112663626_0001_m_000005_0\n",
      "20/04/14 16:21:14 INFO mapred.LocalJobRunner: Starting task: attempt_local112663626_0001_m_000006_0\n",
      "20/04/14 16:21:14 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:21:14 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:21:14 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: Processing split: file:/opt/data/nasa/NASA_access_log_Jul95:201326592+3915776\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: numReduceTasks: 1\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:21:14 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/./map_reduce.py, map]\n",
      "20/04/14 16:21:14 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:14 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:14 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:14 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:14 INFO streaming.PipeMapRed: Records R/W=2431/1\n",
      "20/04/14 16:21:14 INFO streaming.PipeMapRed: R/W/S=10000/8168/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:14 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "20/04/14 16:21:14 INFO streaming.PipeMapRed: mapRedFinished\n",
      "20/04/14 16:21:14 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:21:14 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: bufstart = 0; bufend = 183000; bufvoid = 104857600\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26068348(104273392); length = 146049/6553600\n",
      "20/04/14 16:21:14 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:21:14 INFO mapred.Task: Task:attempt_local112663626_0001_m_000006_0 is done. And is in the process of committing\n",
      "20/04/14 16:21:14 INFO mapred.LocalJobRunner: Records R/W=2431/1\n",
      "20/04/14 16:21:14 INFO mapred.Task: Task 'attempt_local112663626_0001_m_000006_0' done.\n",
      "20/04/14 16:21:14 INFO mapred.Task: Final Counters for attempt_local112663626_0001_m_000006_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=205407731\n",
      "\t\tFILE: Number of bytes written=13837958\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=36514\n",
      "\t\tMap output records=36513\n",
      "\t\tMap output bytes=183000\n",
      "\t\tMap output materialized bytes=256032\n",
      "\t\tInput split bytes=93\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=36513\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=13\n",
      "\t\tTotal committed heap usage (bytes)=499122176\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3915776\n",
      "20/04/14 16:21:14 INFO mapred.LocalJobRunner: Finishing task: attempt_local112663626_0001_m_000006_0\n",
      "20/04/14 16:21:14 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "20/04/14 16:21:14 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "20/04/14 16:21:14 INFO mapred.LocalJobRunner: Starting task: attempt_local112663626_0001_r_000000_0\n",
      "20/04/14 16:21:14 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:21:14 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:21:14 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:21:14 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@285932f\n",
      "20/04/14 16:21:14 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=349385504, maxSingleShuffleLimit=87346376, mergeThreshold=230594448, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "20/04/14 16:21:14 INFO reduce.EventFetcher: attempt_local112663626_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "20/04/14 16:21:14 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local112663626_0001_m_000003_0 decomp: 2166365 len: 2166369 to MEMORY\n",
      "20/04/14 16:21:14 INFO reduce.InMemoryMapOutput: Read 2166365 bytes from map-output for attempt_local112663626_0001_m_000003_0\n",
      "20/04/14 16:21:14 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2166365, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2166365\n",
      "20/04/14 16:21:14 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local112663626_0001_m_000006_0 decomp: 256028 len: 256032 to MEMORY\n",
      "20/04/14 16:21:14 INFO reduce.InMemoryMapOutput: Read 256028 bytes from map-output for attempt_local112663626_0001_m_000006_0\n",
      "20/04/14 16:21:14 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 256028, inMemoryMapOutputs.size() -> 2, commitMemory -> 2166365, usedMemory ->2422393\n",
      "20/04/14 16:21:14 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local112663626_0001_m_000005_0 decomp: 2183111 len: 2183115 to MEMORY\n",
      "20/04/14 16:21:14 INFO reduce.InMemoryMapOutput: Read 2183111 bytes from map-output for attempt_local112663626_0001_m_000005_0\n",
      "20/04/14 16:21:14 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2183111, inMemoryMapOutputs.size() -> 3, commitMemory -> 2422393, usedMemory ->4605504\n",
      "20/04/14 16:21:14 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local112663626_0001_m_000002_0 decomp: 2181819 len: 2181823 to MEMORY\n",
      "20/04/14 16:21:14 INFO reduce.InMemoryMapOutput: Read 2181819 bytes from map-output for attempt_local112663626_0001_m_000002_0\n",
      "20/04/14 16:21:14 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2181819, inMemoryMapOutputs.size() -> 4, commitMemory -> 4605504, usedMemory ->6787323\n",
      "20/04/14 16:21:14 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local112663626_0001_m_000001_0 decomp: 2165300 len: 2165304 to MEMORY\n",
      "20/04/14 16:21:14 INFO reduce.InMemoryMapOutput: Read 2165300 bytes from map-output for attempt_local112663626_0001_m_000001_0\n",
      "20/04/14 16:21:14 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2165300, inMemoryMapOutputs.size() -> 5, commitMemory -> 6787323, usedMemory ->8952623\n",
      "20/04/14 16:21:14 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local112663626_0001_m_000004_0 decomp: 2183507 len: 2183511 to MEMORY\n",
      "20/04/14 16:21:14 INFO reduce.InMemoryMapOutput: Read 2183507 bytes from map-output for attempt_local112663626_0001_m_000004_0\n",
      "20/04/14 16:21:14 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2183507, inMemoryMapOutputs.size() -> 6, commitMemory -> 8952623, usedMemory ->11136130\n",
      "20/04/14 16:21:14 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local112663626_0001_m_000000_0 decomp: 2138822 len: 2138826 to MEMORY\n",
      "20/04/14 16:21:14 INFO reduce.InMemoryMapOutput: Read 2138822 bytes from map-output for attempt_local112663626_0001_m_000000_0\n",
      "20/04/14 16:21:14 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2138822, inMemoryMapOutputs.size() -> 7, commitMemory -> 11136130, usedMemory ->13274952\n",
      "20/04/14 16:21:14 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "20/04/14 16:21:14 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
      "20/04/14 16:21:14 INFO reduce.MergeManagerImpl: finalMerge called with 7 in-memory map-outputs and 0 on-disk map-outputs\n",
      "20/04/14 16:21:14 INFO mapred.Merger: Merging 7 sorted segments\n",
      "20/04/14 16:21:14 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 13274896 bytes\n",
      "20/04/14 16:21:15 INFO reduce.MergeManagerImpl: Merged 7 segments, 13274952 bytes to disk to satisfy reduce memory limit\n",
      "20/04/14 16:21:15 INFO reduce.MergeManagerImpl: Merging 1 files, 13274944 bytes from disk\n",
      "20/04/14 16:21:15 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "20/04/14 16:21:15 INFO mapred.Merger: Merging 1 sorted segments\n",
      "20/04/14 16:21:15 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 13274932 bytes\n",
      "20/04/14 16:21:15 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/./map_reduce.py, reduce]\n",
      "20/04/14 16:21:15 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "20/04/14 16:21:15 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=200000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=300000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=400000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=500000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=600000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=700000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:15 INFO streaming.PipeMapRed: R/W/S=800000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:16 INFO streaming.PipeMapRed: R/W/S=900000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "20/04/14 16:21:16 INFO streaming.PipeMapRed: R/W/S=1000000/0/0 in:1000000=1000000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "20/04/14 16:21:16 INFO streaming.PipeMapRed: R/W/S=1100000/0/0 in:1100000=1100000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "20/04/14 16:21:16 INFO streaming.PipeMapRed: R/W/S=1200000/0/0 in:1200000=1200000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "20/04/14 16:21:16 INFO streaming.PipeMapRed: R/W/S=1300000/0/0 in:1300000=1300000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "20/04/14 16:21:16 INFO streaming.PipeMapRed: R/W/S=1400000/0/0 in:1400000=1400000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "20/04/14 16:21:16 INFO streaming.PipeMapRed: R/W/S=1500000/0/0 in:1500000=1500000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "20/04/14 16:21:16 INFO streaming.PipeMapRed: R/W/S=1600000/0/0 in:1600000=1600000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "20/04/14 16:21:16 INFO streaming.PipeMapRed: R/W/S=1700000/0/0 in:1700000=1700000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "20/04/14 16:21:16 INFO streaming.PipeMapRed: R/W/S=1800000/0/0 in:1800000=1800000/1 [rec/s] out:0=0/1 [rec/s]\n",
      "20/04/14 16:21:17 INFO streaming.PipeMapRed: Records R/W=1891714/1\n",
      "20/04/14 16:21:17 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "20/04/14 16:21:17 INFO streaming.PipeMapRed: mapRedFinished\n",
      "20/04/14 16:21:17 INFO mapred.Task: Task:attempt_local112663626_0001_r_000000_0 is done. And is in the process of committing\n",
      "20/04/14 16:21:17 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
      "20/04/14 16:21:17 INFO mapred.Task: Task attempt_local112663626_0001_r_000000_0 is allowed to commit now\n",
      "20/04/14 16:21:17 INFO output.FileOutputCommitter: Saved output of task 'attempt_local112663626_0001_r_000000_0' to file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/output_nasa/_temporary/0/task_local112663626_0001_r_000000\n",
      "20/04/14 16:21:17 INFO mapred.LocalJobRunner: Records R/W=1891714/1 > reduce\n",
      "20/04/14 16:21:17 INFO mapred.Task: Task 'attempt_local112663626_0001_r_000000_0' done.\n",
      "20/04/14 16:21:17 INFO mapred.Task: Final Counters for attempt_local112663626_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=231957879\n",
      "\t\tFILE: Number of bytes written=27112937\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=13274980\n",
      "\t\tReduce input records=1891714\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=1891714\n",
      "\t\tShuffled Maps =7\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=7\n",
      "\t\tGC time elapsed (ms)=29\n",
      "\t\tTotal committed heap usage (bytes)=506986496\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=35\n",
      "20/04/14 16:21:17 INFO mapred.LocalJobRunner: Finishing task: attempt_local112663626_0001_r_000000_0\n",
      "20/04/14 16:21:17 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "20/04/14 16:21:18 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "20/04/14 16:21:18 INFO mapreduce.Job: Job job_local112663626_0001 completed successfully\n",
      "20/04/14 16:21:18 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1142928338\n",
      "\t\tFILE: Number of bytes written=89764103\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1891715\n",
      "\t\tMap output records=1891714\n",
      "\t\tMap output bytes=9491510\n",
      "\t\tMap output materialized bytes=13274980\n",
      "\t\tInput split bytes=651\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=13274980\n",
      "\t\tReduce input records=1891714\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=3783428\n",
      "\t\tShuffled Maps =7\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=7\n",
      "\t\tGC time elapsed (ms)=92\n",
      "\t\tTotal committed heap usage (bytes)=4095213568\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=205266944\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=35\n",
      "20/04/14 16:21:18 INFO streaming.StreamJob: Output directory: output_nasa\n"
     ]
    }
   ],
   "source": [
    "!hadoop jar ${HADOOP_HOME}/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar -files map_reduce.py -input /opt/data/nasa/ -mapper 'map_reduce.py map' -reducer 'map_reduce.py reduce' -output output_nasa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.3 Run the program Terasort on 1 GB of data - each record that TeraGen generates is 100 Bytes in size:\n",
    "\n",
    "    hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar teragen <number_of_records> <output_directory>\n",
    "\n",
    "    hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar terasort <input_directory> <output_directory>\n",
    "    \n",
    "    hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar teravalidate <input_directory> <output_directory>\n",
    "\n",
    "Measure the runtime for each step and plot the results! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/04/14 16:21:47 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "20/04/14 16:21:47 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "20/04/14 16:21:47 INFO terasort.TeraGen: Generating 10000000 using 1\n",
      "20/04/14 16:21:47 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "20/04/14 16:21:48 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1818680397_0001\n",
      "20/04/14 16:21:48 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "20/04/14 16:21:48 INFO mapreduce.Job: Running job: job_local1818680397_0001\n",
      "20/04/14 16:21:48 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "20/04/14 16:21:48 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:21:48 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:21:48 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "20/04/14 16:21:48 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "20/04/14 16:21:48 INFO mapred.LocalJobRunner: Starting task: attempt_local1818680397_0001_m_000000_0\n",
      "20/04/14 16:21:48 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:21:48 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:21:48 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:21:48 INFO mapred.MapTask: Processing split: org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeInputSplit@6bf006d\n",
      "20/04/14 16:21:49 INFO mapreduce.Job: Job job_local1818680397_0001 running in uber mode : false\n",
      "20/04/14 16:21:49 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "20/04/14 16:21:57 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:21:57 INFO mapred.Task: Task:attempt_local1818680397_0001_m_000000_0 is done. And is in the process of committing\n",
      "20/04/14 16:21:57 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:21:57 INFO mapred.Task: Task attempt_local1818680397_0001_m_000000_0 is allowed to commit now\n",
      "20/04/14 16:21:57 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1818680397_0001_m_000000_0' to file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/_temporary/0/task_local1818680397_0001_m_000000\n",
      "20/04/14 16:21:57 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:21:57 INFO mapred.Task: Task 'attempt_local1818680397_0001_m_000000_0' done.\n",
      "20/04/14 16:21:57 INFO mapred.Task: Final Counters for attempt_local1818680397_0001_m_000000_0: Counters: 16\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=302059\n",
      "\t\tFILE: Number of bytes written=1008533985\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10000000\n",
      "\t\tMap output records=10000000\n",
      "\t\tInput split bytes=82\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=93\n",
      "\t\tTotal committed heap usage (bytes)=491782144\n",
      "\torg.apache.hadoop.examples.terasort.TeraGen$Counters\n",
      "\t\tCHECKSUM=21472776955442690\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1007812508\n",
      "20/04/14 16:21:57 INFO mapred.LocalJobRunner: Finishing task: attempt_local1818680397_0001_m_000000_0\n",
      "20/04/14 16:21:57 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "20/04/14 16:21:58 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "20/04/14 16:21:58 INFO mapreduce.Job: Job job_local1818680397_0001 completed successfully\n",
      "20/04/14 16:21:58 INFO mapreduce.Job: Counters: 16\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=302059\n",
      "\t\tFILE: Number of bytes written=1008533985\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10000000\n",
      "\t\tMap output records=10000000\n",
      "\t\tInput split bytes=82\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=93\n",
      "\t\tTotal committed heap usage (bytes)=491782144\n",
      "\torg.apache.hadoop.examples.terasort.TeraGen$Counters\n",
      "\t\tCHECKSUM=21472776955442690\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1007812508\n",
      "13.98user 1.61system 0:11.44elapsed 136%CPU (0avgtext+0avgdata 271660maxresident)k\n",
      "0inputs+1971912outputs (0major+73046minor)pagefaults 0swaps\n"
     ]
    }
   ],
   "source": [
    "!time hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar teragen 10000000 teragen_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/04/14 16:22:26 INFO terasort.TeraSort: starting\n",
      "20/04/14 16:22:27 INFO input.FileInputFormat: Total input files to process : 1\n",
      "Spent 26ms computing base-splits.\n",
      "Spent 2ms computing TeraScheduler splits.\n",
      "Computing input splits took 28ms\n",
      "Sampling 10 splits of 30\n",
      "Making 1 from 100000 sampled records\n",
      "Computing parititions took 305ms\n",
      "Spent 336ms computing partitions.\n",
      "20/04/14 16:22:27 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "20/04/14 16:22:27 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "20/04/14 16:22:27 INFO mapreduce.JobSubmitter: number of splits:30\n",
      "20/04/14 16:22:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1685999779_0001\n",
      "20/04/14 16:22:27 INFO mapred.LocalDistributedCacheManager: Creating symlink: /tmp/hadoop-jupyter-ter-akopyan-118531-8d8bf/mapred/local/1586881347825/_partition.lst <- /home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/_partition.lst\n",
      "20/04/14 16:22:27 INFO mapred.LocalDistributedCacheManager: Localized file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/terasort_out/_partition.lst as file:/tmp/hadoop-jupyter-ter-akopyan-118531-8d8bf/mapred/local/1586881347825/_partition.lst\n",
      "20/04/14 16:22:27 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "20/04/14 16:22:27 INFO mapreduce.Job: Running job: job_local1685999779_0001\n",
      "20/04/14 16:22:27 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "20/04/14 16:22:27 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:27 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:27 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "20/04/14 16:22:28 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "20/04/14 16:22:28 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000000_0\n",
      "20/04/14 16:22:28 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:28 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:28 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:28 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:0+33554432\n",
      "20/04/14 16:22:28 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:28 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:28 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:28 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:28 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:28 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:28 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:28 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:28 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:28 INFO mapred.MapTask: bufstart = 0; bufend = 34225590; bufvoid = 104857600\n",
      "20/04/14 16:22:28 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872220(99488880); length = 1342177/6553600\n",
      "20/04/14 16:22:28 INFO mapreduce.Job: Job job_local1685999779_0001 running in uber mode : false\n",
      "20/04/14 16:22:28 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "20/04/14 16:22:29 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:29 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000000_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:29 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:29 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000000_0' done.\n",
      "20/04/14 16:22:29 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=44285430\n",
      "\t\tFILE: Number of bytes written=35627029\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335545\n",
      "\t\tMap output records=335545\n",
      "\t\tMap output bytes=34225590\n",
      "\t\tMap output materialized bytes=34896686\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335545\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33824768\n",
      "20/04/14 16:22:29 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000000_0\n",
      "20/04/14 16:22:29 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000001_0\n",
      "20/04/14 16:22:29 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:29 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:29 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:29 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:33554432+33554432\n",
      "20/04/14 16:22:29 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:29 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:29 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:29 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:29 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:29 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:29 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:29 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:29 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:29 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:29 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:29 INFO mapreduce.Job:  map 3% reduce 0%\n",
      "20/04/14 16:22:30 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:30 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000001_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:30 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:30 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000001_0' done.\n",
      "20/04/14 16:22:30 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000001_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=78118438\n",
      "\t\tFILE: Number of bytes written=70523643\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:30 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000001_0\n",
      "20/04/14 16:22:30 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000002_0\n",
      "20/04/14 16:22:30 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:30 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:30 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:30 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:67108864+33554432\n",
      "20/04/14 16:22:30 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:30 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:30 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:30 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:30 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:30 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:30 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:30 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:30 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:30 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:30 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:30 INFO mapreduce.Job:  map 7% reduce 0%\n",
      "20/04/14 16:22:31 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:31 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000002_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:31 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:31 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000002_0' done.\n",
      "20/04/14 16:22:31 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000002_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=111951446\n",
      "\t\tFILE: Number of bytes written=105420257\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:31 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000002_0\n",
      "20/04/14 16:22:31 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000003_0\n",
      "20/04/14 16:22:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:31 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:100663296+33554432\n",
      "20/04/14 16:22:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:31 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:31 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:31 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:31 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:31 INFO mapred.MapTask: bufstart = 0; bufend = 34225590; bufvoid = 104857600\n",
      "20/04/14 16:22:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872220(99488880); length = 1342177/6553600\n",
      "20/04/14 16:22:31 INFO mapreduce.Job:  map 10% reduce 0%\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:32 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000003_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:32 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:32 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000003_0' done.\n",
      "20/04/14 16:22:32 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000003_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=145784454\n",
      "\t\tFILE: Number of bytes written=140316975\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335545\n",
      "\t\tMap output records=335545\n",
      "\t\tMap output bytes=34225590\n",
      "\t\tMap output materialized bytes=34896686\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335545\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=25\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000003_0\n",
      "20/04/14 16:22:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000004_0\n",
      "20/04/14 16:22:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:939524096+33554432\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:32 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:32 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: bufstart = 0; bufend = 34225590; bufvoid = 104857600\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872220(99488880); length = 1342177/6553600\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:32 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000004_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:32 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:32 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000004_0' done.\n",
      "20/04/14 16:22:32 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000004_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=179617462\n",
      "\t\tFILE: Number of bytes written=175213693\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335545\n",
      "\t\tMap output records=335545\n",
      "\t\tMap output bytes=34225590\n",
      "\t\tMap output materialized bytes=34896686\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335545\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=16\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000004_0\n",
      "20/04/14 16:22:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000005_0\n",
      "20/04/14 16:22:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:905969664+33554432\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:32 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "20/04/14 16:22:32 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:32 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:33 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:33 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000005_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:33 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:33 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000005_0' done.\n",
      "20/04/14 16:22:33 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000005_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=213450470\n",
      "\t\tFILE: Number of bytes written=210110307\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=11\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000005_0\n",
      "20/04/14 16:22:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000006_0\n",
      "20/04/14 16:22:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:33 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:872415232+33554432\n",
      "20/04/14 16:22:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:33 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:33 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:33 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:33 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:33 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:33 INFO mapreduce.Job:  map 20% reduce 0%\n",
      "20/04/14 16:22:34 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:34 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000006_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:34 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:34 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000006_0' done.\n",
      "20/04/14 16:22:34 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000006_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=247283478\n",
      "\t\tFILE: Number of bytes written=245006921\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=13\n",
      "\t\tTotal committed heap usage (bytes)=500695040\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000006_0\n",
      "20/04/14 16:22:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000007_0\n",
      "20/04/14 16:22:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:34 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:838860800+33554432\n",
      "20/04/14 16:22:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:34 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:34 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:34 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:34 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:34 INFO mapred.MapTask: bufstart = 0; bufend = 34225590; bufvoid = 104857600\n",
      "20/04/14 16:22:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872220(99488880); length = 1342177/6553600\n",
      "20/04/14 16:22:34 INFO mapreduce.Job:  map 23% reduce 0%\n",
      "20/04/14 16:22:35 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:35 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000007_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:35 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:35 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000007_0' done.\n",
      "20/04/14 16:22:35 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000007_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=281116443\n",
      "\t\tFILE: Number of bytes written=279903639\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335545\n",
      "\t\tMap output records=335545\n",
      "\t\tMap output bytes=34225590\n",
      "\t\tMap output materialized bytes=34896686\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335545\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=18\n",
      "\t\tTotal committed heap usage (bytes)=505413632\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000007_0\n",
      "20/04/14 16:22:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000008_0\n",
      "20/04/14 16:22:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:35 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:805306368+33554432\n",
      "20/04/14 16:22:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:35 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:35 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:35 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:35 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:35 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:35 INFO mapreduce.Job:  map 27% reduce 0%\n",
      "20/04/14 16:22:36 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:36 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000008_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:36 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:36 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000008_0' done.\n",
      "20/04/14 16:22:36 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000008_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=314941216\n",
      "\t\tFILE: Number of bytes written=314800253\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=16\n",
      "\t\tTotal committed heap usage (bytes)=505413632\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33820672\n",
      "20/04/14 16:22:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000008_0\n",
      "20/04/14 16:22:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000009_0\n",
      "20/04/14 16:22:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:36 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:771751936+33554432\n",
      "20/04/14 16:22:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:36 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:36 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:36 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:36 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:36 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:36 INFO mapreduce.Job:  map 30% reduce 0%\n",
      "20/04/14 16:22:36 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:37 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000009_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:37 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:37 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000009_0' done.\n",
      "20/04/14 16:22:37 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000009_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=348774181\n",
      "\t\tFILE: Number of bytes written=349696867\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=10\n",
      "\t\tTotal committed heap usage (bytes)=521666560\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000009_0\n",
      "20/04/14 16:22:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000010_0\n",
      "20/04/14 16:22:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:738197504+33554432\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:37 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:37 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:37 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000010_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:37 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:37 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000010_0' done.\n",
      "20/04/14 16:22:37 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000010_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=382606634\n",
      "\t\tFILE: Number of bytes written=384593481\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=508035072\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000010_0\n",
      "20/04/14 16:22:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000011_0\n",
      "20/04/14 16:22:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:37 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:704643072+33554432\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:37 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:37 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: bufstart = 0; bufend = 34225590; bufvoid = 104857600\n",
      "20/04/14 16:22:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872220(99488880); length = 1342177/6553600\n",
      "20/04/14 16:22:37 INFO mapreduce.Job:  map 37% reduce 0%\n",
      "20/04/14 16:22:38 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:38 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000011_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:38 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:38 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000011_0' done.\n",
      "20/04/14 16:22:38 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000011_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=416439087\n",
      "\t\tFILE: Number of bytes written=419490199\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335545\n",
      "\t\tMap output records=335545\n",
      "\t\tMap output bytes=34225590\n",
      "\t\tMap output materialized bytes=34896686\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335545\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=521666560\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:38 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000011_0\n",
      "20/04/14 16:22:38 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000012_0\n",
      "20/04/14 16:22:38 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:38 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:38 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:38 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:671088640+33554432\n",
      "20/04/14 16:22:38 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:38 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:38 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:38 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:38 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:38 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:38 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:38 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:38 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:38 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:38 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:38 INFO mapreduce.Job:  map 40% reduce 0%\n",
      "20/04/14 16:22:39 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:39 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000012_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:39 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:39 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000012_0' done.\n",
      "20/04/14 16:22:39 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000012_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=450271540\n",
      "\t\tFILE: Number of bytes written=454386813\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=503316480\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000012_0\n",
      "20/04/14 16:22:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000013_0\n",
      "20/04/14 16:22:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:39 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:637534208+33554432\n",
      "20/04/14 16:22:39 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:39 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:39 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:39 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:39 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:39 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:39 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:39 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:39 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:39 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:39 INFO mapreduce.Job:  map 43% reduce 0%\n",
      "20/04/14 16:22:40 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:40 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000013_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:40 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:40 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000013_0' done.\n",
      "20/04/14 16:22:40 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000013_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=484103481\n",
      "\t\tFILE: Number of bytes written=489283427\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=509607936\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:40 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000013_0\n",
      "20/04/14 16:22:40 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000014_0\n",
      "20/04/14 16:22:40 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:40 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:40 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:40 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:603979776+33554432\n",
      "20/04/14 16:22:40 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:40 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:40 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:40 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:40 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:40 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:40 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:40 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:40 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:40 INFO mapred.MapTask: bufstart = 0; bufend = 34225590; bufvoid = 104857600\n",
      "20/04/14 16:22:40 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872220(99488880); length = 1342177/6553600\n",
      "20/04/14 16:22:40 INFO mapreduce.Job:  map 47% reduce 0%\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:41 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000014_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:41 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:41 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000014_0' done.\n",
      "20/04/14 16:22:41 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000014_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=517935422\n",
      "\t\tFILE: Number of bytes written=524180145\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335545\n",
      "\t\tMap output records=335545\n",
      "\t\tMap output bytes=34225590\n",
      "\t\tMap output materialized bytes=34896686\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335545\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=5\n",
      "\t\tTotal committed heap usage (bytes)=496500736\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:41 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000014_0\n",
      "20/04/14 16:22:41 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000015_0\n",
      "20/04/14 16:22:41 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:41 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:41 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:570425344+33554432\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:41 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:41 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:41 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000015_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:41 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:41 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000015_0' done.\n",
      "20/04/14 16:22:41 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000015_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=551767363\n",
      "\t\tFILE: Number of bytes written=559076759\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=8\n",
      "\t\tTotal committed heap usage (bytes)=503316480\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:41 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000015_0\n",
      "20/04/14 16:22:41 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000016_0\n",
      "20/04/14 16:22:41 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:41 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:41 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:536870912+33554432\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:41 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:41 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "20/04/14 16:22:42 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:42 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:42 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000016_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:42 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:42 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000016_0' done.\n",
      "20/04/14 16:22:42 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000016_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=585598792\n",
      "\t\tFILE: Number of bytes written=593973373\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=3\n",
      "\t\tTotal committed heap usage (bytes)=490209280\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:42 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000016_0\n",
      "20/04/14 16:22:42 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000017_0\n",
      "20/04/14 16:22:42 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:42 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:42 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:503316480+33554432\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:42 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:42 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: bufstart = 0; bufend = 34225590; bufvoid = 104857600\n",
      "20/04/14 16:22:42 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872220(99488880); length = 1342177/6553600\n",
      "20/04/14 16:22:42 INFO mapreduce.Job:  map 57% reduce 0%\n",
      "20/04/14 16:22:43 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:43 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000017_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:43 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:43 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000017_0' done.\n",
      "20/04/14 16:22:43 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000017_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=619430221\n",
      "\t\tFILE: Number of bytes written=628870091\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335545\n",
      "\t\tMap output records=335545\n",
      "\t\tMap output bytes=34225590\n",
      "\t\tMap output materialized bytes=34896686\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335545\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=5\n",
      "\t\tTotal committed heap usage (bytes)=495976448\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:43 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000017_0\n",
      "20/04/14 16:22:43 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000018_0\n",
      "20/04/14 16:22:43 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:43 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:43 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:43 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:469762048+33554432\n",
      "20/04/14 16:22:43 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:43 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:43 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:43 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:43 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:43 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:43 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:43 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:43 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:43 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:43 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:43 INFO mapreduce.Job:  map 60% reduce 0%\n",
      "20/04/14 16:22:44 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:44 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000018_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:44 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:44 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000018_0' done.\n",
      "20/04/14 16:22:44 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000018_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=653261650\n",
      "\t\tFILE: Number of bytes written=663766705\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=484442112\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:44 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000018_0\n",
      "20/04/14 16:22:44 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000019_0\n",
      "20/04/14 16:22:44 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:44 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:44 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:44 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:436207616+33554432\n",
      "20/04/14 16:22:44 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:44 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:44 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:44 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:44 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:44 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:44 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:44 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:44 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:44 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:44 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:44 INFO mapreduce.Job:  map 63% reduce 0%\n",
      "20/04/14 16:22:45 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:45 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000019_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:45 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:45 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000019_0' done.\n",
      "20/04/14 16:22:45 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000019_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=687092567\n",
      "\t\tFILE: Number of bytes written=698663319\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=490209280\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:45 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000019_0\n",
      "20/04/14 16:22:45 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000020_0\n",
      "20/04/14 16:22:45 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:45 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:45 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:45 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:402653184+33554432\n",
      "20/04/14 16:22:45 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:45 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:45 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:45 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:45 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:45 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:45 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:45 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:45 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:45 INFO mapred.MapTask: bufstart = 0; bufend = 34225590; bufvoid = 104857600\n",
      "20/04/14 16:22:45 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872220(99488880); length = 1342177/6553600\n",
      "20/04/14 16:22:45 INFO mapreduce.Job:  map 67% reduce 0%\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:46 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000020_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:46 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:46 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000020_0' done.\n",
      "20/04/14 16:22:46 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000020_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=720923484\n",
      "\t\tFILE: Number of bytes written=733560037\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335545\n",
      "\t\tMap output records=335545\n",
      "\t\tMap output bytes=34225590\n",
      "\t\tMap output materialized bytes=34896686\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335545\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=3\n",
      "\t\tTotal committed heap usage (bytes)=479199232\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:46 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000020_0\n",
      "20/04/14 16:22:46 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000021_0\n",
      "20/04/14 16:22:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:46 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:46 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:369098752+33554432\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:46 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:46 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:46 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000021_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:46 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:46 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000021_0' done.\n",
      "20/04/14 16:22:46 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000021_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=754754401\n",
      "\t\tFILE: Number of bytes written=768456651\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=483917824\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:46 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000021_0\n",
      "20/04/14 16:22:46 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000022_0\n",
      "20/04/14 16:22:46 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:46 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:46 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:335544320+33554432\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:46 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:46 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "20/04/14 16:22:47 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:47 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:47 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000022_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:47 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:47 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000022_0' done.\n",
      "20/04/14 16:22:47 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000022_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=788584806\n",
      "\t\tFILE: Number of bytes written=803353265\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=3\n",
      "\t\tTotal committed heap usage (bytes)=473956352\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:47 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000022_0\n",
      "20/04/14 16:22:47 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000023_0\n",
      "20/04/14 16:22:47 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:47 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:47 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:301989888+33554432\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:47 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:47 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: bufstart = 0; bufend = 34225590; bufvoid = 104857600\n",
      "20/04/14 16:22:47 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872220(99488880); length = 1342177/6553600\n",
      "20/04/14 16:22:47 INFO mapreduce.Job:  map 77% reduce 0%\n",
      "20/04/14 16:22:48 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:48 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000023_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:48 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:48 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000023_0' done.\n",
      "20/04/14 16:22:48 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000023_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=822415211\n",
      "\t\tFILE: Number of bytes written=838249983\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335545\n",
      "\t\tMap output records=335545\n",
      "\t\tMap output bytes=34225590\n",
      "\t\tMap output materialized bytes=34896686\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335545\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=477626368\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:48 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000023_0\n",
      "20/04/14 16:22:48 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000024_0\n",
      "20/04/14 16:22:48 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:48 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:48 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:48 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:268435456+33554432\n",
      "20/04/14 16:22:48 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:48 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:48 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:48 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:48 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:48 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:48 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:48 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:48 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:48 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:48 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:48 INFO mapreduce.Job:  map 80% reduce 0%\n",
      "20/04/14 16:22:49 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:49 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000024_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:49 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:49 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000024_0' done.\n",
      "20/04/14 16:22:49 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000024_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=856245616\n",
      "\t\tFILE: Number of bytes written=873146597\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=469237760\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:49 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000024_0\n",
      "20/04/14 16:22:49 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000025_0\n",
      "20/04/14 16:22:49 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:49 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:49 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:49 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:234881024+33554432\n",
      "20/04/14 16:22:49 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:49 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:49 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:49 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:49 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:49 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:49 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:49 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:49 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:49 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:49 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:49 INFO mapreduce.Job:  map 83% reduce 0%\n",
      "20/04/14 16:22:50 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:50 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000025_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:50 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:50 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000025_0' done.\n",
      "20/04/14 16:22:50 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000025_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=890075509\n",
      "\t\tFILE: Number of bytes written=908043211\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=3\n",
      "\t\tTotal committed heap usage (bytes)=472907776\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:50 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000025_0\n",
      "20/04/14 16:22:50 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000026_0\n",
      "20/04/14 16:22:50 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:50 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:50 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:50 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:201326592+33554432\n",
      "20/04/14 16:22:50 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:50 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:50 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:50 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:50 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:50 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:50 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:50 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:50 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:50 INFO mapred.MapTask: bufstart = 0; bufend = 34225590; bufvoid = 104857600\n",
      "20/04/14 16:22:50 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872220(99488880); length = 1342177/6553600\n",
      "20/04/14 16:22:50 INFO mapreduce.Job:  map 87% reduce 0%\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:51 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000026_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:51 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:51 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000026_0' done.\n",
      "20/04/14 16:22:51 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000026_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=923905402\n",
      "\t\tFILE: Number of bytes written=942939929\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335545\n",
      "\t\tMap output records=335545\n",
      "\t\tMap output bytes=34225590\n",
      "\t\tMap output materialized bytes=34896686\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335545\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=94\n",
      "\t\tTotal committed heap usage (bytes)=381157376\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:51 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000026_0\n",
      "20/04/14 16:22:51 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000027_0\n",
      "20/04/14 16:22:51 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:51 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:51 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:167772160+33554432\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:51 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:51 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:51 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000027_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:51 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:51 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000027_0' done.\n",
      "20/04/14 16:22:51 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000027_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=957735295\n",
      "\t\tFILE: Number of bytes written=977836543\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=381157376\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:51 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000027_0\n",
      "20/04/14 16:22:51 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000028_0\n",
      "20/04/14 16:22:51 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:51 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:51 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:134217728+33554432\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:51 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:51 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "20/04/14 16:22:52 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:52 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: bufstart = 0; bufend = 34225488; bufvoid = 104857600\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 24872224(99488896); length = 1342173/6553600\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:52 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000028_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:52 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:52 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000028_0' done.\n",
      "20/04/14 16:22:52 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000028_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=991564676\n",
      "\t\tFILE: Number of bytes written=1012733157\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=335544\n",
      "\t\tMap output records=335544\n",
      "\t\tMap output bytes=34225488\n",
      "\t\tMap output materialized bytes=34896582\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=335544\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=465043456\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=33828864\n",
      "20/04/14 16:22:52 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000028_0\n",
      "20/04/14 16:22:52 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_m_000029_0\n",
      "20/04/14 16:22:52 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:52 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:52 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teragen_out/part-m-00000:973078528+26921472\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:22:52 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:22:52 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: bufstart = 0; bufend = 27459828; bufvoid = 104857600\n",
      "20/04/14 16:22:52 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25137544(100550176); length = 1076853/6553600\n",
      "20/04/14 16:22:53 INFO mapreduce.Job:  map 97% reduce 0%\n",
      "20/04/14 16:22:53 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:22:53 INFO mapred.Task: Task:attempt_local1685999779_0001_m_000029_0 is done. And is in the process of committing\n",
      "20/04/14 16:22:53 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:22:53 INFO mapred.Task: Task 'attempt_local1685999779_0001_m_000029_0' done.\n",
      "20/04/14 16:22:53 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_m_000029_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1018701085\n",
      "\t\tFILE: Number of bytes written=1040731451\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=269214\n",
      "\t\tMap output records=269214\n",
      "\t\tMap output bytes=27459828\n",
      "\t\tMap output materialized bytes=27998262\n",
      "\t\tInput split bytes=169\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=269214\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=473432064\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=27135892\n",
      "20/04/14 16:22:53 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_m_000029_0\n",
      "20/04/14 16:22:53 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "20/04/14 16:22:53 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "20/04/14 16:22:53 INFO mapred.LocalJobRunner: Starting task: attempt_local1685999779_0001_r_000000_0\n",
      "20/04/14 16:22:53 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:22:53 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:22:53 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:22:53 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2aaebb5b\n",
      "20/04/14 16:22:53 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "20/04/14 16:22:53 INFO reduce.EventFetcher: attempt_local1685999779_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "20/04/14 16:22:53 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000017_0 decomp: 34896682 len: 34896686 to MEMORY\n",
      "20/04/14 16:22:53 INFO reduce.InMemoryMapOutput: Read 34896682 bytes from map-output for attempt_local1685999779_0001_m_000017_0\n",
      "20/04/14 16:22:53 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896682, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->34896682\n",
      "20/04/14 16:22:53 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000004_0 decomp: 34896682 len: 34896686 to MEMORY\n",
      "20/04/14 16:22:53 INFO reduce.InMemoryMapOutput: Read 34896682 bytes from map-output for attempt_local1685999779_0001_m_000004_0\n",
      "20/04/14 16:22:53 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896682, inMemoryMapOutputs.size() -> 2, commitMemory -> 34896682, usedMemory ->69793364\n",
      "20/04/14 16:22:53 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000029_0 decomp: 27998258 len: 27998262 to MEMORY\n",
      "20/04/14 16:22:53 INFO reduce.InMemoryMapOutput: Read 27998258 bytes from map-output for attempt_local1685999779_0001_m_000029_0\n",
      "20/04/14 16:22:53 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 27998258, inMemoryMapOutputs.size() -> 3, commitMemory -> 69793364, usedMemory ->97791622\n",
      "20/04/14 16:22:53 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000019_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:53 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000019_0\n",
      "20/04/14 16:22:53 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 4, commitMemory -> 97791622, usedMemory ->132688200\n",
      "20/04/14 16:22:53 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000006_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:53 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000006_0\n",
      "20/04/14 16:22:53 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 5, commitMemory -> 132688200, usedMemory ->167584778\n",
      "20/04/14 16:22:53 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000018_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:53 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000018_0\n",
      "20/04/14 16:22:53 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 6, commitMemory -> 167584778, usedMemory ->202481356\n",
      "20/04/14 16:22:53 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000005_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:53 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000005_0\n",
      "20/04/14 16:22:53 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 7, commitMemory -> 202481356, usedMemory ->237377934\n",
      "20/04/14 16:22:53 INFO reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=237377934 > mergeThreshold=220663392. Current usedMemory=237377934\n",
      "20/04/14 16:22:53 INFO reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments\n",
      "20/04/14 16:22:53 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000027_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:53 INFO reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...\n",
      "20/04/14 16:22:53 INFO mapred.Merger: Merging 7 sorted segments\n",
      "20/04/14 16:22:53 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 237377843 bytes\n",
      "20/04/14 16:22:53 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000027_0\n",
      "20/04/14 16:22:53 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->272274512\n",
      "20/04/14 16:22:54 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "20/04/14 16:22:54 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000014_0 decomp: 34896682 len: 34896686 to MEMORY\n",
      "20/04/14 16:22:54 INFO reduce.InMemoryMapOutput: Read 34896682 bytes from map-output for attempt_local1685999779_0001_m_000014_0\n",
      "20/04/14 16:22:54 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896682, inMemoryMapOutputs.size() -> 2, commitMemory -> 34896578, usedMemory ->307171194\n",
      "20/04/14 16:22:54 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000001_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:54 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000001_0\n",
      "20/04/14 16:22:54 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 3, commitMemory -> 69793260, usedMemory ->342067772\n",
      "20/04/14 16:22:54 INFO reduce.LocalFetcher: fetcher#1 - MergeManager returned Status.WAIT ...\n",
      "20/04/14 16:22:55 INFO reduce.MergeManagerImpl: attempt_local1685999779_0001_r_000000_0 Merge of the 7 files in-memory complete. Local file is /tmp/hadoop-jupyter-ter-akopyan-118531-8d8bf/mapred/local/localRunner/jupyter-ter-akopyan-118531-8d8bf/jobcache/job_local1685999779_0001/attempt_local1685999779_0001_r_000000_0/output/map_29.out.merged of size 237377926\n",
      "20/04/14 16:22:55 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000026_0 decomp: 34896682 len: 34896686 to MEMORY\n",
      "20/04/14 16:22:55 INFO reduce.InMemoryMapOutput: Read 34896682 bytes from map-output for attempt_local1685999779_0001_m_000026_0\n",
      "20/04/14 16:22:55 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896682, inMemoryMapOutputs.size() -> 4, commitMemory -> 104689838, usedMemory ->139586520\n",
      "20/04/14 16:22:55 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000013_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:55 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000013_0\n",
      "20/04/14 16:22:55 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 5, commitMemory -> 139586520, usedMemory ->174483098\n",
      "20/04/14 16:22:55 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000016_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:55 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000016_0\n",
      "20/04/14 16:22:55 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 6, commitMemory -> 174483098, usedMemory ->209379676\n",
      "20/04/14 16:22:55 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000003_0 decomp: 34896682 len: 34896686 to MEMORY\n",
      "20/04/14 16:22:55 INFO reduce.InMemoryMapOutput: Read 34896682 bytes from map-output for attempt_local1685999779_0001_m_000003_0\n",
      "20/04/14 16:22:55 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896682, inMemoryMapOutputs.size() -> 7, commitMemory -> 209379676, usedMemory ->244276358\n",
      "20/04/14 16:22:55 INFO reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=244276358 > mergeThreshold=220663392. Current usedMemory=244276358\n",
      "20/04/14 16:22:55 INFO reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments\n",
      "20/04/14 16:22:55 INFO reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...\n",
      "20/04/14 16:22:55 INFO mapred.Merger: Merging 7 sorted segments\n",
      "20/04/14 16:22:55 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 244276267 bytes\n",
      "20/04/14 16:22:55 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000028_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:55 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000028_0\n",
      "20/04/14 16:22:55 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->279172936\n",
      "20/04/14 16:22:55 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000015_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:55 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000015_0\n",
      "20/04/14 16:22:55 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 2, commitMemory -> 34896578, usedMemory ->314069514\n",
      "20/04/14 16:22:55 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000002_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:55 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000002_0\n",
      "20/04/14 16:22:55 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 3, commitMemory -> 69793156, usedMemory ->348966092\n",
      "20/04/14 16:22:55 INFO reduce.LocalFetcher: fetcher#1 - MergeManager returned Status.WAIT ...\n",
      "20/04/14 16:22:56 INFO reduce.MergeManagerImpl: attempt_local1685999779_0001_r_000000_0 Merge of the 7 files in-memory complete. Local file is /tmp/hadoop-jupyter-ter-akopyan-118531-8d8bf/mapred/local/localRunner/jupyter-ter-akopyan-118531-8d8bf/jobcache/job_local1685999779_0001/attempt_local1685999779_0001_r_000000_0/output/map_27.out.merged of size 244276350\n",
      "20/04/14 16:22:56 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000024_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:57 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000024_0\n",
      "20/04/14 16:22:57 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 4, commitMemory -> 104689734, usedMemory ->139586312\n",
      "20/04/14 16:22:57 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000011_0 decomp: 34896682 len: 34896686 to MEMORY\n",
      "20/04/14 16:22:57 INFO reduce.InMemoryMapOutput: Read 34896682 bytes from map-output for attempt_local1685999779_0001_m_000011_0\n",
      "20/04/14 16:22:57 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896682, inMemoryMapOutputs.size() -> 5, commitMemory -> 139586312, usedMemory ->174482994\n",
      "20/04/14 16:22:57 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000023_0 decomp: 34896682 len: 34896686 to MEMORY\n",
      "20/04/14 16:22:57 INFO reduce.InMemoryMapOutput: Read 34896682 bytes from map-output for attempt_local1685999779_0001_m_000023_0\n",
      "20/04/14 16:22:57 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896682, inMemoryMapOutputs.size() -> 6, commitMemory -> 174482994, usedMemory ->209379676\n",
      "20/04/14 16:22:57 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000010_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:57 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000010_0\n",
      "20/04/14 16:22:57 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 7, commitMemory -> 209379676, usedMemory ->244276254\n",
      "20/04/14 16:22:57 INFO reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=244276254 > mergeThreshold=220663392. Current usedMemory=244276254\n",
      "20/04/14 16:22:57 INFO reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments\n",
      "20/04/14 16:22:57 INFO reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...\n",
      "20/04/14 16:22:57 INFO mapred.Merger: Merging 7 sorted segments\n",
      "20/04/14 16:22:57 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 244276163 bytes\n",
      "20/04/14 16:22:57 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000000_0 decomp: 34896682 len: 34896686 to MEMORY\n",
      "20/04/14 16:22:57 INFO reduce.InMemoryMapOutput: Read 34896682 bytes from map-output for attempt_local1685999779_0001_m_000000_0\n",
      "20/04/14 16:22:57 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896682, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->279172936\n",
      "20/04/14 16:22:57 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000025_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:57 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000025_0\n",
      "20/04/14 16:22:57 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 2, commitMemory -> 34896682, usedMemory ->314069514\n",
      "20/04/14 16:22:57 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000012_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:57 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000012_0\n",
      "20/04/14 16:22:57 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 3, commitMemory -> 69793260, usedMemory ->348966092\n",
      "20/04/14 16:22:57 INFO reduce.LocalFetcher: fetcher#1 - MergeManager returned Status.WAIT ...\n",
      "20/04/14 16:22:58 INFO reduce.MergeManagerImpl: attempt_local1685999779_0001_r_000000_0 Merge of the 7 files in-memory complete. Local file is /tmp/hadoop-jupyter-ter-akopyan-118531-8d8bf/mapred/local/localRunner/jupyter-ter-akopyan-118531-8d8bf/jobcache/job_local1685999779_0001/attempt_local1685999779_0001_r_000000_0/output/map_28.out.merged of size 244276246\n",
      "20/04/14 16:22:58 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000008_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:58 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000008_0\n",
      "20/04/14 16:22:58 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 4, commitMemory -> 104689838, usedMemory ->139586416\n",
      "20/04/14 16:22:58 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000020_0 decomp: 34896682 len: 34896686 to MEMORY\n",
      "20/04/14 16:22:58 INFO reduce.InMemoryMapOutput: Read 34896682 bytes from map-output for attempt_local1685999779_0001_m_000020_0\n",
      "20/04/14 16:22:58 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896682, inMemoryMapOutputs.size() -> 5, commitMemory -> 139586416, usedMemory ->174483098\n",
      "20/04/14 16:22:58 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000007_0 decomp: 34896682 len: 34896686 to MEMORY\n",
      "20/04/14 16:22:58 INFO reduce.InMemoryMapOutput: Read 34896682 bytes from map-output for attempt_local1685999779_0001_m_000007_0\n",
      "20/04/14 16:22:58 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896682, inMemoryMapOutputs.size() -> 6, commitMemory -> 174483098, usedMemory ->209379780\n",
      "20/04/14 16:22:58 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000022_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:58 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000022_0\n",
      "20/04/14 16:22:58 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 7, commitMemory -> 209379780, usedMemory ->244276358\n",
      "20/04/14 16:22:58 INFO reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=244276358 > mergeThreshold=220663392. Current usedMemory=244276358\n",
      "20/04/14 16:22:58 INFO reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments\n",
      "20/04/14 16:22:58 INFO reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...\n",
      "20/04/14 16:22:58 INFO mapred.Merger: Merging 7 sorted segments\n",
      "20/04/14 16:22:58 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 244276267 bytes\n",
      "20/04/14 16:22:58 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000009_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:58 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000009_0\n",
      "20/04/14 16:22:58 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->279172936\n",
      "20/04/14 16:22:58 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1685999779_0001_m_000021_0 decomp: 34896578 len: 34896582 to MEMORY\n",
      "20/04/14 16:22:59 INFO reduce.InMemoryMapOutput: Read 34896578 bytes from map-output for attempt_local1685999779_0001_m_000021_0\n",
      "20/04/14 16:22:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 34896578, inMemoryMapOutputs.size() -> 2, commitMemory -> 34896578, usedMemory ->314069514\n",
      "20/04/14 16:22:59 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "20/04/14 16:22:59 INFO mapred.LocalJobRunner: 30 / 30 copied.\n",
      "20/04/14 16:23:00 INFO reduce.MergeManagerImpl: attempt_local1685999779_0001_r_000000_0 Merge of the 7 files in-memory complete. Local file is /tmp/hadoop-jupyter-ter-akopyan-118531-8d8bf/mapred/local/localRunner/jupyter-ter-akopyan-118531-8d8bf/jobcache/job_local1685999779_0001/attempt_local1685999779_0001_r_000000_0/output/map_25.out.merged of size 244276350\n",
      "20/04/14 16:23:00 INFO reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 4 on-disk map-outputs\n",
      "20/04/14 16:23:00 INFO mapred.Merger: Merging 2 sorted segments\n",
      "20/04/14 16:23:00 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 69793130 bytes\n",
      "20/04/14 16:23:00 INFO reduce.MergeManagerImpl: Merged 2 segments, 69793156 bytes to disk to satisfy reduce memory limit\n",
      "20/04/14 16:23:00 INFO reduce.MergeManagerImpl: Merging 5 files, 1040000030 bytes from disk\n",
      "20/04/14 16:23:00 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "20/04/14 16:23:00 INFO mapred.Merger: Merging 5 sorted segments\n",
      "20/04/14 16:23:00 INFO mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 1039999945 bytes\n",
      "20/04/14 16:23:00 INFO mapred.LocalJobRunner: 30 / 30 copied.\n",
      "20/04/14 16:23:00 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "20/04/14 16:23:05 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "20/04/14 16:23:06 INFO mapreduce.Job:  map 100% reduce 81%\n",
      "20/04/14 16:23:11 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "20/04/14 16:23:11 INFO mapred.Task: Task:attempt_local1685999779_0001_r_000000_0 is done. And is in the process of committing\n",
      "20/04/14 16:23:11 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "20/04/14 16:23:11 INFO mapred.Task: Task attempt_local1685999779_0001_r_000000_0 is allowed to commit now\n",
      "20/04/14 16:23:11 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1685999779_0001_r_000000_0' to file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/terasort_out/_temporary/0/task_local1685999779_0001_r_000000\n",
      "20/04/14 16:23:11 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "20/04/14 16:23:11 INFO mapred.Task: Task 'attempt_local1685999779_0001_r_000000_0' done.\n",
      "20/04/14 16:23:11 INFO mapred.Task: Final Counters for attempt_local1685999779_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3098702351\n",
      "\t\tFILE: Number of bytes written=3088543989\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10000000\n",
      "\t\tReduce shuffle bytes=1040000180\n",
      "\t\tReduce input records=10000000\n",
      "\t\tReduce output records=10000000\n",
      "\t\tSpilled Records=10000000\n",
      "\t\tShuffled Maps =30\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=30\n",
      "\t\tGC time elapsed (ms)=776\n",
      "\t\tTotal committed heap usage (bytes)=529530880\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1007812508\n",
      "20/04/14 16:23:11 INFO mapred.LocalJobRunner: Finishing task: attempt_local1685999779_0001_r_000000_0\n",
      "20/04/14 16:23:11 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "20/04/14 16:23:12 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "20/04/14 16:23:12 INFO mapreduce.Job: Job job_local1685999779_0001 completed successfully\n",
      "20/04/14 16:23:12 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=19137437611\n",
      "\t\tFILE: Number of bytes written=19330498709\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10000000\n",
      "\t\tMap output records=10000000\n",
      "\t\tMap output bytes=1020000000\n",
      "\t\tMap output materialized bytes=1040000180\n",
      "\t\tInput split bytes=5070\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10000000\n",
      "\t\tReduce shuffle bytes=1040000180\n",
      "\t\tReduce input records=10000000\n",
      "\t\tReduce output records=10000000\n",
      "\t\tSpilled Records=20000000\n",
      "\t\tShuffled Maps =30\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=30\n",
      "\t\tGC time elapsed (ms)=1049\n",
      "\t\tTotal committed heap usage (bytes)=15212740608\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1008160660\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1007812508\n",
      "20/04/14 16:23:12 INFO terasort.TeraSort: done\n",
      "49.23user 8.17system 0:45.82elapsed 125%CPU (0avgtext+0avgdata 653852maxresident)k\n",
      "0inputs+6034808outputs (0major+470247minor)pagefaults 0swaps\n"
     ]
    }
   ],
   "source": [
    "!time hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar terasort teragen_out/ terasort_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/04/14 16:33:35 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "20/04/14 16:33:35 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "20/04/14 16:33:35 INFO input.FileInputFormat: Total input files to process : 1\n",
      "Spent 31ms computing base-splits.\n",
      "Spent 7ms computing TeraScheduler splits.\n",
      "20/04/14 16:33:35 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "20/04/14 16:33:35 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1534357759_0001\n",
      "20/04/14 16:33:35 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "20/04/14 16:33:35 INFO mapreduce.Job: Running job: job_local1534357759_0001\n",
      "20/04/14 16:33:35 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "20/04/14 16:33:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:33:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:33:35 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "20/04/14 16:33:35 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "20/04/14 16:33:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1534357759_0001_m_000000_0\n",
      "20/04/14 16:33:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:33:35 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:33:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:33:35 INFO mapred.MapTask: Processing split: file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/terasort_out/part-r-00000:0+1000000000\n",
      "20/04/14 16:33:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "20/04/14 16:33:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "20/04/14 16:33:35 INFO mapred.MapTask: soft limit at 83886080\n",
      "20/04/14 16:33:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "20/04/14 16:33:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "20/04/14 16:33:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "20/04/14 16:33:36 INFO mapreduce.Job: Job job_local1534357759_0001 running in uber mode : false\n",
      "20/04/14 16:33:36 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "20/04/14 16:33:39 INFO mapred.LocalJobRunner: \n",
      "20/04/14 16:33:39 INFO mapred.MapTask: Starting flush of map output\n",
      "20/04/14 16:33:39 INFO mapred.MapTask: Spilling map output\n",
      "20/04/14 16:33:39 INFO mapred.MapTask: bufstart = 0; bufend = 82; bufvoid = 104857600\n",
      "20/04/14 16:33:39 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600\n",
      "20/04/14 16:33:39 INFO mapred.MapTask: Finished spill 0\n",
      "20/04/14 16:33:39 INFO mapred.Task: Task:attempt_local1534357759_0001_m_000000_0 is done. And is in the process of committing\n",
      "20/04/14 16:33:39 INFO mapred.LocalJobRunner: map\n",
      "20/04/14 16:33:39 INFO mapred.Task: Task 'attempt_local1534357759_0001_m_000000_0' done.\n",
      "20/04/14 16:33:39 INFO mapred.Task: Final Counters for attempt_local1534357759_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1008114669\n",
      "\t\tFILE: Number of bytes written=722851\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10000000\n",
      "\t\tMap output records=3\n",
      "\t\tMap output bytes=82\n",
      "\t\tMap output materialized bytes=94\n",
      "\t\tInput split bytes=170\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1007812508\n",
      "20/04/14 16:33:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1534357759_0001_m_000000_0\n",
      "20/04/14 16:33:39 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "20/04/14 16:33:39 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "20/04/14 16:33:39 INFO mapred.LocalJobRunner: Starting task: attempt_local1534357759_0001_r_000000_0\n",
      "20/04/14 16:33:39 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "20/04/14 16:33:39 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "20/04/14 16:33:39 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "20/04/14 16:33:39 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@367ce7fc\n",
      "20/04/14 16:33:39 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=360395552, maxSingleShuffleLimit=90098888, mergeThreshold=237861072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "20/04/14 16:33:39 INFO reduce.EventFetcher: attempt_local1534357759_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "20/04/14 16:33:39 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1534357759_0001_m_000000_0 decomp: 90 len: 94 to MEMORY\n",
      "20/04/14 16:33:39 INFO reduce.InMemoryMapOutput: Read 90 bytes from map-output for attempt_local1534357759_0001_m_000000_0\n",
      "20/04/14 16:33:39 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 90, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->90\n",
      "20/04/14 16:33:39 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "20/04/14 16:33:39 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "20/04/14 16:33:39 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "20/04/14 16:33:39 INFO mapred.Merger: Merging 1 sorted segments\n",
      "20/04/14 16:33:39 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 79 bytes\n",
      "20/04/14 16:33:39 INFO reduce.MergeManagerImpl: Merged 1 segments, 90 bytes to disk to satisfy reduce memory limit\n",
      "20/04/14 16:33:39 INFO reduce.MergeManagerImpl: Merging 1 files, 94 bytes from disk\n",
      "20/04/14 16:33:39 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "20/04/14 16:33:39 INFO mapred.Merger: Merging 1 sorted segments\n",
      "20/04/14 16:33:39 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 79 bytes\n",
      "20/04/14 16:33:39 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "20/04/14 16:33:39 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "20/04/14 16:33:39 INFO mapred.Task: Task:attempt_local1534357759_0001_r_000000_0 is done. And is in the process of committing\n",
      "20/04/14 16:33:39 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "20/04/14 16:33:39 INFO mapred.Task: Task attempt_local1534357759_0001_r_000000_0 is allowed to commit now\n",
      "20/04/14 16:33:39 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1534357759_0001_r_000000_0' to file:/home/jupyter-ter-akopyan-118531-8d8bf/exercise-students-2020/03_MapReduce/teravalidate_out/_temporary/0/task_local1534357759_0001_r_000000\n",
      "20/04/14 16:33:39 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "20/04/14 16:33:39 INFO mapred.Task: Task 'attempt_local1534357759_0001_r_000000_0' done.\n",
      "20/04/14 16:33:39 INFO mapred.Task: Final Counters for attempt_local1534357759_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1008114889\n",
      "\t\tFILE: Number of bytes written=722981\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce shuffle bytes=94\n",
      "\t\tReduce input records=3\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=3\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=514850816\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=36\n",
      "20/04/14 16:33:39 INFO mapred.LocalJobRunner: Finishing task: attempt_local1534357759_0001_r_000000_0\n",
      "20/04/14 16:33:39 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "20/04/14 16:33:40 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "20/04/14 16:33:40 INFO mapreduce.Job: Job job_local1534357759_0001 completed successfully\n",
      "20/04/14 16:33:40 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2016229558\n",
      "\t\tFILE: Number of bytes written=1445832\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10000000\n",
      "\t\tMap output records=3\n",
      "\t\tMap output bytes=82\n",
      "\t\tMap output materialized bytes=94\n",
      "\t\tInput split bytes=170\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce shuffle bytes=94\n",
      "\t\tReduce input records=3\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=6\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=1029701632\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1007812508\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=36\n",
      "10.28user 0.85system 0:06.35elapsed 175%CPU (0avgtext+0avgdata 462416maxresident)k\n",
      "0inputs+3560outputs (0major+129688minor)pagefaults 0swaps\n"
     ]
    }
   ],
   "source": [
    "!time hadoop jar ${HADOOP_HOME}/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.5.jar teravalidate terasort_out teravalidate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
